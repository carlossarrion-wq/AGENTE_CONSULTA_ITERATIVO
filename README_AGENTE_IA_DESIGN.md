# Agente IA de Consulta Darwin - DiseÃ±o ArquitectÃ³nico

Sistema de agente conversacional inteligente para consulta de la base de conocimiento Darwin con capacidades de streaming y procesamiento de herramientas.

## ğŸ¯ Objetivo

DiseÃ±ar un agente IA modular que permita la consulta interactiva de la base de conocimiento Darwin mediante:
- Interfaz de chat en modo texto
- Procesamiento inteligente de respuestas LLM
- EjecuciÃ³n automÃ¡tica de herramientas de bÃºsqueda
- Soporte futuro para streaming de respuestas

## ğŸ—ï¸ Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              AGENTE IA DARWIN                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Chat Interface â”‚    â”‚ Request Handler â”‚    â”‚ LLM Comm Module â”‚                â”‚
â”‚  â”‚                 â”‚â—„â”€â”€â–ºâ”‚  (Orchestrator) â”‚â—„â”€â”€â–ºâ”‚                 â”‚                â”‚
â”‚  â”‚ â€¢ Input Handler â”‚    â”‚ â€¢ Flow Control  â”‚    â”‚ â€¢ Request Mgmt  â”‚                â”‚
â”‚  â”‚ â€¢ Display Mgmt  â”‚    â”‚ â€¢ State Mgmt    â”‚    â”‚ â€¢ Response Hdlr â”‚                â”‚
â”‚  â”‚ â€¢ User Interact â”‚    â”‚ â€¢ Tool Parsing  â”‚    â”‚ â€¢ Connection    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚           â”‚                       â”‚                       â”‚                        â”‚
â”‚           â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚                        â”‚
â”‚           â”‚              â”‚ Tool Execution  â”‚              â”‚                        â”‚
â”‚           â”‚              â”‚     Engine      â”‚              â”‚                        â”‚
â”‚           â”‚              â”‚ â€¢ XML Parser    â”‚              â”‚                        â”‚
â”‚           â”‚              â”‚ â€¢ Tool Router   â”‚              â”‚                        â”‚
â”‚           â”‚              â”‚ â€¢ Result Merger â”‚              â”‚                        â”‚
â”‚           â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                        â”‚
â”‚           â”‚                       â”‚                       â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚Response Formatterâ”‚    â”‚ Config Manager  â”‚    â”‚Knowledge Base   â”‚                â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚   Interface     â”‚                â”‚
â”‚  â”‚ â€¢ Static Format â”‚    â”‚ â€¢ Settings Load â”‚    â”‚ â€¢ Semantic      â”‚                â”‚
â”‚  â”‚ â€¢ Stream Format â”‚    â”‚ â€¢ Env Variables â”‚    â”‚ â€¢ Lexical       â”‚                â”‚
â”‚  â”‚ â€¢ XML Filter    â”‚    â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Regex         â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ File Content  â”‚                â”‚
â”‚                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ MÃ³dulos Principales

### 1. Chat Interface Module
**Responsabilidad**: Interfaz de usuario para interacciÃ³n conversacional

**Componentes**:
- **Input Handler**: Captura y valida entrada del usuario
- **Display Manager**: 
  - Static Display (implementaciÃ³n actual)
  - Streaming Display (futuro)
- **User Interaction**: GestiÃ³n de sesiÃ³n y contexto

**Funcionalidades**:
- Captura de consultas del usuario
- VisualizaciÃ³n de respuestas formateadas
- Manejo de historial de conversaciÃ³n
- Soporte futuro para streaming progresivo

### 2. Request Handler/Orchestrator
**Responsabilidad**: CoordinaciÃ³n central del flujo de procesamiento

**Componentes**:
- **Flow Control**: GestiÃ³n del flujo de conversaciÃ³n
- **State Management**: Mantenimiento del estado de la sesiÃ³n
- **Tool Parsing**: AnÃ¡lisis de respuestas LLM para identificar herramientas

**Funcionalidades**:
- RecepciÃ³n de consultas del chat interface
- EnvÃ­o de requests al LLM
- Parsing de respuestas XML del LLM
- CoordinaciÃ³n de ejecuciÃ³n de herramientas
- GestiÃ³n de estado conversacional

### 3. LLM Communication Module
**Responsabilidad**: ComunicaciÃ³n con el modelo de lenguaje

**Componentes**:
- **Request Manager**: ConstrucciÃ³n y envÃ­o de requests
- **Response Handler**:
  - Batch Response (implementaciÃ³n actual)
  - Stream Response (futuro)
- **Connection Manager**: GestiÃ³n de conexiones y autenticaciÃ³n
- **Prompt Cache Manager**: GestiÃ³n de cache de prompts (CRÃTICO)

**Funcionalidades**:
- ConstrucciÃ³n de prompts con contexto
- **Prompt Caching**: Cache inteligente de contexto conversacional
- EnvÃ­o de requests a AWS Bedrock
- RecepciÃ³n de respuestas (batch/stream)
- Manejo de errores y reintentos
- OptimizaciÃ³n de tokens mediante cache

### 4. Tool Execution Engine
**Responsabilidad**: EjecuciÃ³n de herramientas de bÃºsqueda

**Componentes**:
- **XML Parser**: AnÃ¡lisis de tags XML en respuestas LLM
- **Tool Router**: Enrutamiento a herramientas especÃ­ficas
- **Result Merger**: ConsolidaciÃ³n de resultados mÃºltiples

**Funcionalidades**:
- Parsing de `<SEMANTIC_SEARCH>`, `<LEXICAL_SEARCH>`, etc.
- EjecuciÃ³n de herramientas con parÃ¡metros extraÃ­dos
- ConsolidaciÃ³n de resultados mÃºltiples
- Manejo de errores de herramientas

### 5. Configuration Manager
**Responsabilidad**: GestiÃ³n de configuraciÃ³n del sistema

**Componentes**:
- **Settings Loader**: Carga de archivos de configuraciÃ³n
- **Environment Variables**: GestiÃ³n de variables de entorno
- **Validation**: ValidaciÃ³n de configuraciÃ³n

**Funcionalidades**:
- Carga de `config.yaml`
- GestiÃ³n de credenciales AWS
- ConfiguraciÃ³n de herramientas de bÃºsqueda
- ConfiguraciÃ³n de streaming (futuro)

### 6. Knowledge Base Interface
**Responsabilidad**: Interfaz con herramientas de bÃºsqueda existentes

**Componentes**:
- **Semantic Search**: IntegraciÃ³n con `semantic_search.py`
- **Lexical Search**: IntegraciÃ³n con `lexical_search.py`
- **Regex Search**: IntegraciÃ³n con `regex_search.py`
- **File Content**: IntegraciÃ³n con `get_file_content.py`

**Funcionalidades**:
- AbstracciÃ³n de herramientas de bÃºsqueda
- NormalizaciÃ³n de parÃ¡metros
- EstandarizaciÃ³n de respuestas

### 7. Response Formatter
**Responsabilidad**: Formateo de respuestas para presentaciÃ³n

**Componentes**:
- **Static Formatter**: Formateo tradicional (actual)
- **Stream Processor**: Procesamiento de streaming (futuro)
- **XML Filter**: Filtrado de contenido tÃ©cnico

**Funcionalidades**:
- Formateo de respuestas LLM
- IntegraciÃ³n de resultados de herramientas
- Filtrado de contenido tÃ©cnico (streaming)

## ğŸ”„ Flujo de Datos

### Flujo Principal con Prompt Caching
```
Usuario Input â†’ Chat Interface â†’ Request Handler â†’ LLM Communication
                                        â†“
                              Prompt Cache Manager
                                        â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         GESTIÃ“N DE CACHE            â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ â€¢ Verificar cache existente         â”‚
                    â”‚ â€¢ Construir prompt incremental      â”‚
                    â”‚ â€¢ Aplicar cache de contexto         â”‚
                    â”‚ â€¢ Optimizar tokens enviados         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
                              Respuesta LLM con XML
                                        â†“
                              Tool Execution Engine
                                        â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        EJECUCIÃ“N HERRAMIENTAS       â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ <SEMANTIC_SEARCH> â†’ semantic_search â”‚
                    â”‚ <LEXICAL_SEARCH> â†’ lexical_search   â”‚
                    â”‚ <REGEX_SEARCH> â†’ regex_search       â”‚
                    â”‚ <GET_FILE_CONTENT> â†’ get_file_contentâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
                              ConsolidaciÃ³n Resultados
                                        â†“
                              Response Formatter
                                        â†“
                              Chat Interface â†’ Usuario
                                        â†“
                              Actualizar Cache Conversacional
```

### Flujo con Streaming (Futuro)
```
Usuario Input â†’ Chat Interface â†’ Request Handler â†’ LLM Communication
                                        â†“
                                 Stream Response
                                        â†“
                              Response Parser
                                        â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        FILTRADO EN TIEMPO REAL      â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ XML Tags â†’ [OCULTAR]                â”‚
                    â”‚ <SEMANTIC_SEARCH> â†’ 'BÃºsqueda...'   â”‚
                    â”‚ <LEXICAL_SEARCH> â†’ 'BÃºsqueda...'    â”‚
                    â”‚ <REGEX_SEARCH> â†’ 'BÃºsqueda...'      â”‚
                    â”‚ <GET_FILE_CONTENT> â†’ 'Obteniendo...'â”‚
                    â”‚ Texto normal â†’ [MOSTRAR]            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
                              Stream Processor
                                        â†“
                            Display Manager (Streaming)
                                        â†“
                              Chat Interface â†’ Usuario
```

## ğŸ—‚ï¸ Estructura de Archivos Propuesta

```
AGENTE_CONSULTA_ITERATIVO/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/                          # MÃ³dulos del agente IA
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat_interface.py           # Interfaz de chat
â”‚   â”‚   â”œâ”€â”€ request_handler.py          # Orquestador principal
â”‚   â”‚   â”œâ”€â”€ llm_communication.py        # ComunicaciÃ³n LLM
â”‚   â”‚   â”œâ”€â”€ prompt_cache_manager.py     # GestiÃ³n cache prompts (NUEVO)
â”‚   â”‚   â”œâ”€â”€ conversation_manager.py     # GestiÃ³n historial conversacional (NUEVO)
â”‚   â”‚   â”œâ”€â”€ tool_executor.py            # EjecuciÃ³n de herramientas
â”‚   â”‚   â”œâ”€â”€ config_manager.py           # GestiÃ³n de configuraciÃ³n
â”‚   â”‚   â”œâ”€â”€ knowledge_interface.py      # Interfaz herramientas bÃºsqueda
â”‚   â”‚   â””â”€â”€ response_formatter.py       # Formateo de respuestas
â”‚   â”œâ”€â”€ streaming/                      # MÃ³dulos streaming (futuro)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ response_parser.py          # Parser streaming
â”‚   â”‚   â”œâ”€â”€ stream_processor.py         # Procesador streaming
â”‚   â”‚   â”œâ”€â”€ display_manager.py          # Gestor display streaming
â”‚   â”‚   â””â”€â”€ filter_rules.py             # Reglas de filtrado
â”‚   â”œâ”€â”€ [herramientas existentes...]    # Herramientas de bÃºsqueda actuales
â”‚   â”‚   â”œâ”€â”€ semantic_search.py
â”‚   â”‚   â”œâ”€â”€ lexical_search.py
â”‚   â”‚   â”œâ”€â”€ regex_search.py
â”‚   â”‚   â”œâ”€â”€ get_file_content.py
â”‚   â”‚   â””â”€â”€ common.py
â”‚   â””â”€â”€ main.py                         # Punto de entrada principal
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml                     # ConfiguraciÃ³n principal
â”‚   â””â”€â”€ streaming_config.yaml           # ConfiguraciÃ³n streaming (futuro)
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ system_prompt.md                # Prompt del sistema (desde ejemplo_llamada_003.md)
â””â”€â”€ [archivos existentes...]
```

## âš™ï¸ ConfiguraciÃ³n del Sistema

### ConfiguraciÃ³n Principal (config.yaml)
```yaml
# ConfiguraciÃ³n existente de herramientas de bÃºsqueda
opensearch:
  host: "vpc-rag-opensearch-clean-qodnaopeuroal2f6intbz7i5xy.eu-west-1.es.amazonaws.com"
  index_name: "rag-documents-darwin"

bedrock:
  region_name: "eu-west-1"
  model_id: "amazon.titan-embed-image-v1"

# Nueva configuraciÃ³n del agente
agent:
  max_conversation_turns: 50
  max_tools_per_response: 5
  response_timeout_seconds: 120
  
llm:
  model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
  max_tokens: 4000
  temperature: 0.1
  
# ConfiguraciÃ³n crÃ­tica de Prompt Caching
prompt_caching:
  enabled: true                         # FUNDAMENTAL para rendimiento
  cache_ttl_minutes: 60                 # Tiempo de vida del cache
  max_cached_conversations: 100         # MÃ¡ximo conversaciones en cache
  cache_compression: true               # CompresiÃ³n de prompts largos
  incremental_updates: true             # Updates incrementales del contexto
  cache_strategy: "sliding_window"      # Estrategia de cache
  
conversation:
  max_history_turns: 20                 # MÃ¡ximo turnos en historial
  context_window_tokens: 100000         # Ventana de contexto mÃ¡xima
  system_prompt_caching: true           # Cache del system prompt
  tool_results_caching: true            # Cache de resultados de herramientas
  
chat:
  welcome_message: "Â¡Hola! Soy el agente Darwin. Â¿En quÃ© puedo ayudarte?"
  max_history_length: 20
```

### ConfiguraciÃ³n Streaming (streaming_config.yaml - Futuro)
```yaml
streaming:
  enabled: false                        # Por defecto deshabilitado
  buffer_size: 1024
  update_interval: 0.1
  
  # Traducciones de herramientas
  tool_translations:
    SEMANTIC_SEARCH: 'VOY A REALIZAR UNA BÃšSQUEDA SEMÃNTICA SOBRE {document}'
    LEXICAL_SEARCH: 'VOY A REALIZAR UNA BÃšSQUEDA LEXICAL SOBRE {query}'
    REGEX_SEARCH: 'VOY A REALIZAR UNA BÃšSQUEDA POR PATRONES SOBRE {pattern}'
    GET_FILE_CONTENT: 'VOY A OBTENER EL CONTENIDO DEL ARCHIVO {filename}'
  
  # Tags a ocultar
  hidden_tags:
    - 'thinking'
    - 'internal_state'
    - 'debug_info'
  
  # ConfiguraciÃ³n de filtros
  filters:
    show_xml_tags: false
    translate_tool_calls: true
    progressive_display: true
```

## ğŸ’¾ Sistema de Prompt Caching (CRÃTICO)

### Prompt Cache Manager
**Responsabilidad**: GestiÃ³n inteligente del cache de prompts para optimizar rendimiento y costos

**Funcionalidades**:
- **Cache de System Prompt**: El prompt del sistema se cachea una sola vez
- **Cache Conversacional**: Historial de conversaciÃ³n se mantiene en cache
- **Updates Incrementales**: Solo se envÃ­an los nuevos mensajes al LLM
- **CompresiÃ³n Inteligente**: CompresiÃ³n de contexto cuando se acerca al lÃ­mite
- **Sliding Window**: Mantiene ventana deslizante de contexto relevante

**MÃ©todos principales**:
```python
def cache_system_prompt(prompt: str) -> str  # Cachea prompt del sistema
def get_cached_conversation(session_id: str) -> ConversationCache
def update_conversation_cache(session_id: str, new_turn: Turn) -> None
def build_incremental_prompt(session_id: str, user_input: str) -> str
def compress_context_if_needed(context: str) -> str
def invalidate_cache(session_id: str) -> None
```

### Conversation Manager
**Responsabilidad**: GestiÃ³n del historial conversacional y contexto

**Funcionalidades**:
- **Historial Estructurado**: Mantiene estructura de turnos usuario/asistente
- **GestiÃ³n de Tokens**: Monitoreo de uso de tokens por conversaciÃ³n
- **Context Window Management**: GestiÃ³n inteligente de ventana de contexto
- **Tool Results Integration**: IntegraciÃ³n de resultados de herramientas en historial

**MÃ©todos principales**:
```python
def add_user_turn(session_id: str, message: str) -> None
def add_assistant_turn(session_id: str, response: str, tools_used: List[Tool]) -> None
def get_conversation_context(session_id: str) -> str
def trim_context_to_window(context: str, max_tokens: int) -> str
def get_token_count(text: str) -> int
```

### Estrategias de Cache

#### 1. Cache de System Prompt
```python
# El system prompt se cachea una sola vez por sesiÃ³n
CACHED_SYSTEM_PROMPT = """
Eres un agente especializado en consultas sobre la base de conocimiento Darwin...
[Prompt completo desde ejemplo_llamada_003.md]
"""
```

#### 2. Cache Conversacional Incremental
```python
# Estructura de cache conversacional
ConversationCache = {
    "session_id": "uuid-session",
    "system_prompt_hash": "hash-del-system-prompt",
    "turns": [
        {
            "role": "user",
            "content": "Â¿CÃ³mo configurar OAuth?",
            "timestamp": "2025-10-27T09:00:00Z",
            "tokens": 25
        },
        {
            "role": "assistant", 
            "content": "Voy a buscar informaciÃ³n sobre OAuth...",
            "tools_used": ["SEMANTIC_SEARCH"],
            "tool_results": {...},
            "timestamp": "2025-10-27T09:00:15Z",
            "tokens": 150
        }
    ],
    "total_tokens": 175,
    "last_updated": "2025-10-27T09:00:15Z",
    "cache_ttl": "2025-10-27T10:00:15Z"
}
```

#### 3. OptimizaciÃ³n de Tokens
```python
# Solo se envÃ­a al LLM:
# 1. System prompt (cacheado)
# 2. Contexto conversacional necesario
# 3. Nuevo input del usuario

def build_optimized_prompt(session_id: str, new_input: str) -> str:
    cache = get_cached_conversation(session_id)
    
    # Construir prompt incremental
    prompt_parts = [
        get_cached_system_prompt(),  # Cacheado
        build_conversation_context(cache.turns[-10:]),  # Ãšltimos 10 turnos
        f"Human: {new_input}",
        "Assistant:"
    ]
    
    return "\n\n".join(prompt_parts)
```

### Beneficios del Prompt Caching

#### Rendimiento
- **ReducciÃ³n 60-80% en tokens enviados** por request despuÃ©s del primer turno
- **Latencia reducida** al no reenviar contexto completo
- **Throughput mejorado** del sistema

#### Costos
- **Ahorro significativo en costos de tokens** (especialmente en conversaciones largas)
- **OptimizaciÃ³n de uso de API** de AWS Bedrock
- **ROI mejorado** del sistema

#### Escalabilidad
- **Soporte para mÃ¡s conversaciones concurrentes**
- **Menor carga en infraestructura LLM**
- **Mejor experiencia de usuario**

## ğŸ”§ Componentes de Streaming (Futuro)

### Response Parser
**Funcionalidades**:
- AnÃ¡lisis de chunks de streaming en tiempo real
- DetecciÃ³n de tags XML parciales
- ExtracciÃ³n de informaciÃ³n de herramientas
- Filtrado de contenido para display

**MÃ©todos principales**:
```python
def parse_streaming_chunk(chunk: str) -> ParsedChunk
def extract_tool_info(xml_content: str) -> ToolInfo
def filter_display_content(content: str) -> str
```

### Stream Processor
**Funcionalidades**:
- GestiÃ³n de buffer para chunks parciales
- AplicaciÃ³n de filtros en tiempo real
- EnvÃ­o progresivo al display manager
- Mantenimiento de estado de parsing

**MÃ©todos principales**:
```python
def process_stream_chunk(chunk: str) -> None
def apply_real_time_filters(content: str) -> str
def manage_display_buffer() -> None
def track_parsing_state() -> None
```

### Display Manager (Streaming)
**Funcionalidades**:
- ActualizaciÃ³n progresiva de la interfaz
- Manejo de traducciones de herramientas
- GestiÃ³n de buffer de display
- SincronizaciÃ³n con chat interface

**MÃ©todos principales**:
```python
def append_filtered_content(content: str) -> None
def handle_tool_translation(tool_info: ToolInfo) -> None
def update_interface_progressive() -> None
```

## ğŸ¯ Patrones de Uso

### Ejemplo de ConversaciÃ³n con Prompt Caching

#### Turno 1 (Sin Cache)
```
Usuario: "Â¿CÃ³mo configurar OAuth en aplicaciones web?"

[SISTEMA - Primer request]
Tokens enviados: ~8,000 (System Prompt completo + User Input)
Cache: System Prompt cacheado para sesiÃ³n

Agente: Voy a buscar informaciÃ³n sobre configuraciÃ³n OAuth en aplicaciones web.

[Internamente ejecuta: <SEMANTIC_SEARCH>configuraciÃ³n OAuth aplicaciones web</SEMANTIC_SEARCH>]

Agente: He encontrado informaciÃ³n relevante sobre OAuth. SegÃºn la documentaciÃ³n:

1. **ConfiguraciÃ³n bÃ¡sica de OAuth 2.0**:
   - Registrar aplicaciÃ³n en el proveedor OAuth
   - Configurar redirect URIs
   - Obtener client_id y client_secret

2. **ImplementaciÃ³n en aplicaciones web**:
   - Usar flujo Authorization Code
   - Implementar endpoints de callback
   - Gestionar tokens de acceso y refresh

Â¿Te gustarÃ­a que busque informaciÃ³n mÃ¡s especÃ­fica sobre algÃºn aspecto?
```

#### Turno 2 (Con Cache - OPTIMIZADO)
```
Usuario: "SÃ­, busca ejemplos de cÃ³digo para implementar OAuth"

[SISTEMA - Request optimizado con cache]
Tokens enviados: ~1,500 (Solo contexto conversacional + nuevo input)
Ahorro: ~6,500 tokens (81% reducciÃ³n)
Cache: Reutiliza System Prompt + contexto previo

Agente: [Con streaming futuro mostrarÃ­a: "VOY A REALIZAR UNA BÃšSQUEDA POR PATRONES SOBRE cÃ³digo OAuth"]

[Ejecuta bÃºsquedas y presenta resultados...]
```

#### Turno 3+ (Cache Optimizado)
```
Usuario: "Â¿Hay algÃºn ejemplo especÃ­fico para Node.js?"

[SISTEMA - Request ultra-optimizado]
Tokens enviados: ~800 (Contexto mÃ­nimo + nuevo input)
Ahorro: ~7,200 tokens (90% reducciÃ³n)
Cache: Ventana deslizante de contexto relevante
```

### Impacto del Prompt Caching en Conversaciones Largas

```
ConversaciÃ³n de 10 turnos SIN cache:
- Turno 1: 8,000 tokens
- Turno 2: 8,500 tokens (contexto crece)
- Turno 3: 9,000 tokens
- ...
- Turno 10: 15,000 tokens
TOTAL: ~105,000 tokens

ConversaciÃ³n de 10 turnos CON cache:
- Turno 1: 8,000 tokens (inicial)
- Turno 2: 1,500 tokens (cache activo)
- Turno 3: 1,200 tokens
- ...
- Turno 10: 1,000 tokens
TOTAL: ~20,000 tokens

AHORRO: 85,000 tokens (81% reducciÃ³n)
AHORRO ECONÃ“MICO: ~$170 por conversaciÃ³n larga (estimado)
```

### Flujo de Herramientas
```python
# Ejemplo de ejecuciÃ³n de herramientas
tools_executed = [
    {
        "type": "SEMANTIC_SEARCH",
        "query": "configuraciÃ³n OAuth aplicaciones web",
        "results": [...],
        "display_message": "BÃºsqueda semÃ¡ntica sobre OAuth"
    },
    {
        "type": "REGEX_SEARCH", 
        "pattern": "oauth.*client.*secret",
        "results": [...],
        "display_message": "BÃºsqueda de patrones OAuth"
    }
]
```

## ğŸš€ Ventajas del DiseÃ±o

### Modularidad
- **SeparaciÃ³n clara de responsabilidades**
- **Componentes intercambiables**
- **FÃ¡cil testing unitario**
- **Escalabilidad horizontal**

### Extensibilidad
- **Nuevas herramientas fÃ¡ciles de agregar**
- **Soporte para diferentes LLMs**
- **ConfiguraciÃ³n flexible**
- **Plugins de formateo**

### Mantenibilidad
- **CÃ³digo organizado por funcionalidad**
- **ConfiguraciÃ³n centralizada**
- **Logging estructurado**
- **DocumentaciÃ³n integrada**

### Compatibilidad
- **No afecta herramientas existentes**
- **Streaming opcional (futuro)**
- **ConfiguraciÃ³n backward-compatible**
- **MigraciÃ³n gradual**

## ğŸ”® Roadmap de ImplementaciÃ³n

### Fase 1: Core Agent (Actual)
- âœ… DiseÃ±o arquitectÃ³nico
- âœ… DiseÃ±o Prompt Caching (CRÃTICO)
- â³ ImplementaciÃ³n mÃ³dulos bÃ¡sicos
- â³ **ImplementaciÃ³n Prompt Cache Manager (PRIORITARIO)**
- â³ **ImplementaciÃ³n Conversation Manager (PRIORITARIO)**
- â³ IntegraciÃ³n con herramientas existentes
- â³ Testing bÃ¡sico

### Fase 2: Funcionalidades Avanzadas
- â³ OptimizaciÃ³n avanzada de cache
- â³ GestiÃ³n de estado conversacional
- â³ Manejo de errores robusto
- â³ MÃ©tricas de rendimiento de cache
- â³ Logging y monitoreo

### Fase 3: Streaming (Futuro)
- â³ ImplementaciÃ³n response parser
- â³ Stream processor
- â³ Display manager streaming
- â³ ConfiguraciÃ³n streaming

### Fase 4: Mejoras y OptimizaciÃ³n
- â³ Cache inteligente
- â³ MÃ©tricas y analytics
- â³ UI/UX mejorado
- â³ DocumentaciÃ³n completa

## ğŸ“Š Consideraciones TÃ©cnicas

### Rendimiento
- **Prompt Caching (CRÃTICO)**: ReducciÃ³n 60-80% tokens por request
- **Cache de respuestas LLM**
- **Pool de conexiones**
- **Procesamiento asÃ­ncrono**
- **OptimizaciÃ³n de queries**
- **Context Window Management**: GestiÃ³n inteligente de ventana de contexto

### Seguridad
- **ValidaciÃ³n de inputs**
- **SanitizaciÃ³n de outputs**
- **GestiÃ³n segura de credenciales**
- **Logging sin informaciÃ³n sensible**

### Escalabilidad
- **Arquitectura stateless**
- **ConfiguraciÃ³n por entorno**
- **MÃ©tricas de uso**
- **Balanceador de carga ready**

### Monitoreo
- **Logs estructurados**
- **MÃ©tricas de rendimiento**
- **Alertas de errores**
- **Dashboard de uso**

---

**VersiÃ³n**: 1.0.0  
**Fecha**: Octubre 2025  
**Estado**: DiseÃ±o Completado  
**PrÃ³ximo paso**: ImplementaciÃ³n Fase 1
