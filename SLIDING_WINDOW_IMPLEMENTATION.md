# Implementaci√≥n del Mecanismo de Sliding Window

## Problema Identificado

Al realizar m√∫ltiples iteraciones de consulta al LLM, especialmente cuando se utilizan herramientas que devuelven grandes cantidades de contenido (como `get_file_content`), el historial conversacional crece indefinidamente hasta superar el l√≠mite del modelo, generando el siguiente error:

```
ValidationException: Input is too long for requested model.
```

## Soluci√≥n Implementada

Se ha implementado un **mecanismo de sliding window** que mantiene autom√°ticamente el historial conversacional dentro de los l√≠mites del modelo, eliminando las iteraciones m√°s antiguas cuando se alcanza el l√≠mite de tokens.

## Caracter√≠sticas

### 1. Configuraci√≥n Flexible

En `config/config.yaml`:

```yaml
conversation:
  max_history_turns: 15  # N√∫mero m√°ximo de turnos a mantener
  context_window_tokens: 180000  # 90% de 200K tokens (l√≠mite del modelo)
  system_prompt_caching: true
  tool_results_caching: true
  enable_sliding_window: true  # Habilitar ventana deslizante
  min_turns_to_keep: 3  # M√≠nimo de turnos a mantener siempre
```

### 2. L√≠mite de Tokens Configurable

- **Modelo Claude Haiku 4.5**: Soporta 200,000 tokens
- **Configuraci√≥n actual**: 180,000 tokens (90% del l√≠mite)
- **Margen de seguridad**: 20,000 tokens para system prompt y respuesta del modelo

### 3. Funcionamiento Autom√°tico

El sistema aplica autom√°ticamente el sliding window en cada request al LLM:

1. **Antes de enviar el request**: Se calcula el total de tokens en el historial
2. **Si supera el l√≠mite**: Se mantienen solo los turnos m√°s recientes que caben en la ventana
3. **Turnos eliminados**: Los m√°s antiguos se descartan autom√°ticamente
4. **Logging detallado**: Se registra cu√°ntos turnos se mantienen y cu√°ntos se eliminan

### 4. Logging Informativo

Cuando se aplica el sliding window, se registra en los logs:

```
üîÑ Sliding window aplicado:
   ‚Ä¢ L√≠mite de tokens: 180000
   ‚Ä¢ Turnos totales en conversaci√≥n: 20
   ‚Ä¢ Turnos mantenidos en contexto: 5
   ‚Ä¢ Turnos eliminados (m√°s antiguos): 15
   ‚Ä¢ Tokens antes: 600280, despu√©s: ~150080
```

## Archivos Modificados

### 1. `config/config.yaml`
- A√±adida configuraci√≥n `enable_sliding_window: true`
- Ajustado `context_window_tokens: 180000` (90% de 200K)
- A√±adido `min_turns_to_keep: 3`

### 2. `src/agent/llm_communication.py`
- Modificado m√©todo `send_request_with_conversation()`
- Integraci√≥n con `ConversationManager.trim_context_to_window()`
- A√±adido logging detallado del proceso de trimming

### 3. `src/agent/conversation_manager.py`
- Ya conten√≠a el m√©todo `trim_context_to_window()` implementado
- Utiliza un algoritmo de sliding window basado en tokens

## C√≥mo Funciona

### Algoritmo de Sliding Window

```python
def trim_context_to_window(session_id, max_tokens):
    """
    1. Obtener todos los turnos de la conversaci√≥n
    2. Iterar desde el turno m√°s reciente hacia atr√°s
    3. Acumular tokens hasta alcanzar el l√≠mite
    4. Descartar turnos m√°s antiguos que no caben
    5. Retornar contexto trimmed
    """
```

### Ejemplo de Uso

```python
# Conversaci√≥n con 20 turnos (600K tokens)
# L√≠mite: 180K tokens

# Resultado:
# - Se mantienen los √∫ltimos 5 turnos (~150K tokens)
# - Se eliminan los primeros 15 turnos
# - El LLM recibe solo el contexto reciente relevante
```

## Ventajas

1. **Prevenci√≥n de errores**: Evita el error "Input is too long for requested model"
2. **Autom√°tico**: No requiere intervenci√≥n manual
3. **Configurable**: L√≠mites ajustables seg√∫n necesidades
4. **Eficiente**: Mantiene solo el contexto relevante m√°s reciente
5. **Transparente**: Logging detallado del proceso

## Pruebas

Se ha creado un script de prueba completo: `test_sliding_window.py`

### Ejecutar pruebas:

```bash
python3 test_sliding_window.py
```

### Resultados esperados:

```
‚úÖ TODOS LOS TESTS PASARON EXITOSAMENTE
```

## Monitoreo

Para verificar el funcionamiento en producci√≥n, revisar los logs:

```bash
tail -f logs/agent.log | grep "Sliding window"
```

Buscar l√≠neas como:

```
üîÑ Sliding window aplicado:
   ‚Ä¢ L√≠mite de tokens: 180000
   ‚Ä¢ Turnos totales en conversaci√≥n: 25
   ‚Ä¢ Turnos mantenidos en contexto: 6
   ‚Ä¢ Turnos eliminados (m√°s antiguos): 19
```

## Recomendaciones

1. **Ajustar l√≠mite seg√∫n modelo**: Si cambias de modelo, ajusta `context_window_tokens`
2. **Monitorear logs**: Revisa peri√≥dicamente cu√°ntos turnos se eliminan
3. **Optimizar herramientas**: Si una herramienta devuelve demasiado contenido, considera resumirlo
4. **Balance**: Mantener suficiente contexto pero sin saturar el modelo

## Desactivar Sliding Window (No Recomendado)

Si por alguna raz√≥n necesitas desactivar el sliding window:

```yaml
conversation:
  enable_sliding_window: false  # Desactivar (no recomendado)
```

**Advertencia**: Desactivar el sliding window puede causar errores cuando el historial crezca demasiado.

## Soporte

Para m√°s informaci√≥n o problemas:
- Revisar logs en `logs/agent.log`
- Ejecutar tests: `python3 test_sliding_window.py`
- Verificar configuraci√≥n en `config/config.yaml`
